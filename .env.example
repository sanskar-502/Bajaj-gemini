
LLM_PROVIDER=gemini

# --- Provider API Keys (only one is needed based on the provider above) ---
# Get your Gemini API key from Google AI Studio: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_google_ai_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp

# --- Vector Database Configuration ---
# Choose your vector database: "faiss" (local, recommended for getting started) or "pinecone" (cloud)
VECTOR_DB_TYPE=pinecone

# --- Pinecone Settings (only needed if VECTOR_DB_TYPE="pinecone") ---
# Get your Pinecone API key from: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=your_pinecone_index_name_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here



# --- Embedding & Retrieval Settings ---
# A smaller, faster model that runs well on a CPU. Recommended for testing and hackathons.

#A larger, more powerful model. Better accuracy, but requires a GPU for good performance.
# EMBEDDING_MODEL=intfloat/multilingual-e5-large

EMBEDDING_MODEL=all-MiniLM-L6-v2

# --- Performance Tuning ---
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5

# Lower threshold = more results, but potentially more noise. Higher = fewer, more precise results.
SIMILARITY_THRESHOLD=0.4


# --- File and API Server Settings ---
MAX_FILE_SIZE=50 # Max file size in MB
API_HOST=0.0.0.0
API_PORT=8000


# --- File System Paths ---
UPLOAD_DIR=uploads
VECTOR_STORE_DIR=vector_store


# --- Logging ---
LOG_LEVEL=INFO
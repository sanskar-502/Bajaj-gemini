# -----------------------------------------------------------------------------
# LLM-powered Intelligent Queryâ€“Retrieval System - Environment Variables
# -----------------------------------------------------------------------------
# Copy this file to .env and fill in your values.
# Do NOT commit the .env file to your version control system.

# --- Core AI Configuration ---
# Choose your Large Language Model provider: "gemini" or "openai"
LLM_PROVIDER=gemini

# --- Provider API Keys (only one is needed based on the provider above) ---
# Get your Gemini API key from Google AI Studio: https://makersuite.google.com/app/apikey
GEMINI_API_KEY=your_google_ai_api_key_here
GEMINI_MODEL=gemini-1.5-flash-latest

# Get your OpenAI API key from: https://platform.openai.com/api-keys
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-4-turbo


# --- Vector Database Configuration ---
# Choose your vector database: "faiss" (local, recommended for getting started) or "pinecone" (cloud)
VECTOR_DB_TYPE=faiss

# --- Pinecone Settings (only needed if VECTOR_DB_TYPE="pinecone") ---
# Get your Pinecone API key from: https://app.pinecone.io/
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_INDEX_NAME=legal-llm-query


# --- Embedding & Retrieval Settings ---
# A smaller, faster model that runs well on a CPU. Recommended for testing and hackathons.
EMBEDDING_MODEL=all-MiniLM-L6-v2
# A larger, more powerful model. Better accuracy, but requires a GPU for good performance.
# EMBEDDING_MODEL=intfloat/multilingual-e5-large

CHUNK_SIZE=1000
CHUNK_OVERLAP=200
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.7


# --- File and API Server Settings ---
MAX_FILE_SIZE=50 # Max file size in MB
API_HOST=0.0.0.0
API_PORT=8000


# --- File System Paths ---
UPLOAD_DIR=uploads
VECTOR_STORE_DIR=vector_store


# --- Logging ---
LOG_LEVEL=INFO